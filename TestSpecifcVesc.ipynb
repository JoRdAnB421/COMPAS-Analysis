{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eb47bb4-1ddf-427d-a28d-21f6227f62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob; import sys; import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import ode\n",
    "from matplotlib.lines import Line2D\n",
    "from random import choices\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "plt.rcParams.update({'font.size': 17}) # Set a good font size\n",
    "\n",
    "\n",
    "rsol2AU = 0.00465047 # solar radii to au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37223d66-cc21-41bb-9197-8210c0e4eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dir():\n",
    "        '''\n",
    "        Finds the likely location for the petar data files to be stored\n",
    "        and gives the option to autoselect them.\n",
    "\n",
    "        Returns data directory as a string\n",
    "        '''\n",
    "\n",
    "        # Finding possible directories where data could be stored\n",
    "        directories = glob.glob('COMPAS_Output*')\n",
    "\n",
    "        # Create a dictionary to store the available directories and index vals\n",
    "        directoryList = {str(i): directories[i] for i in range(len(directories))}\n",
    "\n",
    "        # Print the available directories\n",
    "        print('Possible Directories:\\n')\n",
    "        for key, val in directoryList.items():\n",
    "                print(key, ':', val)\n",
    "\n",
    "        # Asking what directory the data is stored in and giving a list of potential directories\n",
    "        chooseDirectory = input('\\nWhat directory is the data stored in?  ')\n",
    "        if chooseDirectory in directoryList.keys():\n",
    "                dataDirectory = directoryList[str(chooseDirectory)]\n",
    "\n",
    "        elif os.path.exists(str(chooseDirectory)):\n",
    "                dataDirectory = str(chooseDirectory)\n",
    "\n",
    "        else:\n",
    "                print('Could not find directory\\n')\n",
    "                print('Quitting')\n",
    "                sys.exit()\n",
    "\n",
    "        return dataDirectory\n",
    "    \n",
    "def tdelay(ai,ei,m1,m2):\n",
    "    \"\"\"\n",
    "    Calculates the GW timescale for a given binary\n",
    "    semi-major axis, eccentricty and masses\n",
    "\n",
    "    Input >>> ai = Semi Major axis [Rsol]\n",
    "          ei = eccentricity\n",
    "          m1, m2 = primary/secondary mass [Msol]\n",
    "\n",
    "    Output >>> tGW = merger timescale [yrs]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Defining useful constants\n",
    "    Rsol = 6.9*(10**8.) #in meters\n",
    "    MyrsToSec = 3.15*(10**13.) #time in sec\n",
    "    tobs = 13*(10**3.)*MyrsToSec #Age of MilkyWay\n",
    "\n",
    "    Gsi =  6.6*10**-11. #garavitaional constant in SI\n",
    "    c = 3.*(10**8.) #velocity of light in seconds\n",
    "    AUtoRsol = 214.9 #AU to Rsol\n",
    "    Msol = 2.*(10**30) #Solar mass in kg\n",
    "    betaWithoutMass = (64./5.)*(Gsi**3.0)/(c**5.0)\n",
    "    daysToSeconds = 86400\n",
    "    GyrsToSec = MyrsToSec * 1000\n",
    "    YrsToSec = MyrsToSec/10**6\n",
    "\n",
    "\n",
    "    #----tdelay\n",
    "\n",
    "    #-- Choose ODE integrator\n",
    "    backend = 'dopri5'\n",
    "\n",
    "    l=len(ei)\n",
    "    t_merger=[]\n",
    "\n",
    "    for i in range(l):\n",
    "        a0 = ai[i]*Rsol\n",
    "        m_1 = m1[i]*Msol\n",
    "        m_2 = m2[i]*Msol\n",
    "        e0=ei[i]\n",
    "\n",
    "        # If the initial ecc=0 then we have analytical solution\n",
    "        if e0==0:\n",
    "            beta = betaWithoutMass*m_1*m_2*(m_1+m_2)\n",
    "            Te = (a0**4)/(4*beta)\n",
    "            t_merger.append(Te/YrsToSec)\n",
    "            continue\n",
    "\n",
    "        c0Part1 = a0*(1. - e0**2.0)\n",
    "        c0Part2 = (1.+(121./304.)*e0**2.)**(870./2299.)\n",
    "        c0Part3 = e0**(12./19.)\n",
    "        c0 = c0Part1/(c0Part2*c0Part3)\n",
    "        beta = betaWithoutMass*m_1*m_2*(m_1+m_2)\n",
    "\n",
    "        constant = (12./19.)*(c0**4.)/beta\n",
    "        #print ((1. - e0**2.)**(3./2.))\n",
    "\n",
    "        func = lambda e: constant*((e**(29./19.))*(1. + (121./304.)*e**2.)**(1181./2299.))/((1. - e**2.)**(3./2.))\n",
    "\n",
    "        #-- Create ODE solver object\n",
    "        solver = ode(func).set_integrator(backend)\n",
    "\n",
    "        #-- Define initial and final parameters\n",
    "        T0 = 0        #-- Initial value of T\n",
    "        efinal = 1e-5 #-- Maximum value of e to integrate to\n",
    "\n",
    "        solver.set_initial_value(T0, e0) #.set_f_params(r)\n",
    "\n",
    "        sol = [] #-- Create an empty list to store the output in (here it will be the e list)\n",
    "\n",
    "        #-- Define a function to append the output to our list\n",
    "        def solout(e, T):\n",
    "            sol.append([e, T/YrsToSec])\n",
    "        solver.set_solout(solout)\n",
    "\n",
    "        #-- This line actually integrates the ODE, no loop is required\n",
    "        solver.integrate(efinal)\n",
    "\n",
    "        #-- Convert list to array\n",
    "        sol = np.asarray(sol, dtype=float)\n",
    "\n",
    "        #-- Use sol to find the location\n",
    "\n",
    "        e = sol[:, 0]\n",
    "        T = np.abs(sol[:,1])\n",
    "\n",
    "        t_max = max(np.abs(sol[:,1]))\n",
    "\n",
    "        tm = t_max\n",
    "        #print tm\n",
    "\n",
    "        t_merger.append(tm)\n",
    "\n",
    "    return np.asarray(t_merger)\n",
    "\n",
    "def calcTrh(M, rh):\n",
    "    '''\n",
    "    Calculate the half-mass relaxation timescale for the cluster (Myrs)\n",
    "    \n",
    "    Input >>> M = cluster mass (Msol)\n",
    "          >>> rh = cluster half-mass radius (pc)\n",
    "    \n",
    "    Output >>> trh = relaxation time (Myrs)\n",
    "    '''\n",
    "    \n",
    "    #Define G \n",
    "    G = 0.00449830997959438 # pc^3 Msol^-1 Myrs^-2\n",
    "    \n",
    "    const = 0.138/(50*0.809) # Msol^-1\n",
    "    \n",
    "    return const * np.sqrt((M*rh**3)/(G))\n",
    "\n",
    "def calcTint(M1, M2, a, Mcl, rh, trh):\n",
    "    '''\n",
    "    Calculates the interaction timescale for a hard encounter\n",
    "    \n",
    "    Input >>> M1 = mass 1 (Msol)\n",
    "          >>> M2 = mass 2 (Msol)\n",
    "          >>> a = semimajor axis (AU)\n",
    "          >>> Mcl = cluster Mass (Msol)\n",
    "          >>> rh = cluster half mass radius (pc)\n",
    "          >>> trh = relaxation time (Myrs)\n",
    "          \n",
    "    Output >>> tint = interaction timescale (Myrs)\n",
    "    '''\n",
    "    \n",
    "    # Convert rh to AU\n",
    "    rh*=pc2AU\n",
    "    \n",
    "    binary = (M1*M2)/a\n",
    "    cluster = rh/(Mcl**2)\n",
    "    \n",
    "    return 5 * binary * cluster * trh\n",
    "\n",
    "def calcMergeFromInteractions(m1, m2, semi, tint, N):\n",
    "    '''\n",
    "    Calculate the affect of an interaction and see if it would \n",
    "    lead to a binary that merges. For each binary assume that the \n",
    "    binding energy increases by 40% and the eccentricity is drawn \n",
    "    from a thermal distribution averaged over 10 times\n",
    "    \n",
    "    Input >>> m1, m2 = primary and secondary binary mass (Msol)\n",
    "          >>> Semi = semi-major axis (rsol)\n",
    "          >>> tint = time for an interaction (Myrs)\n",
    "          >>> N = Number of interactions to average over\n",
    "          \n",
    "    Output >>> avgtdelay = coalescence time averaged over 10 interactions (Myrs)\n",
    "    '''\n",
    "    \n",
    "    # Number of binaries\n",
    "    num=m1.size\n",
    "    \n",
    "    # Assume hard encounter increases binding energy by 40%\n",
    "    new_a = semi/1.4\n",
    "    \n",
    "    # Empty array to store all of the Tdelays\n",
    "    delayTime_all = np.zeros(num)\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Draw an eccentricity from a thermal distribution for every binary\n",
    "        esq = np.random.uniform(0,1,num)\n",
    "        e = np.sqrt(esq)\n",
    "        \n",
    "        # Find the merger time for each of the binaries in Myrs and + interaction time\n",
    "        tmerge = tdelay(ai=new_a, ei=e, m1=m1, m2=m2)/1e6\n",
    "        delayTime = tmerge+tint\n",
    "        \n",
    "        # Append to the array we have\n",
    "        delayTime_all = np.vstack((delayTime_all, delayTime))\n",
    "    \n",
    "    # for each binary average the tdelays\n",
    "    delayTime_all = delayTime_all.T\n",
    "    avgtdelay = np.mean(delayTime_all, axis=1)\n",
    "    \n",
    "    return avgtdelay\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e5f954-9427-4043-b355-88295c90385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "G = 1.908e5 # R_sol*(M_sol)^-1*km^2*s^-2 \n",
    "pc2AU = 206265 # Pc -> AU\n",
    "Rsol2AU = 0.00465047 # Rsol -> AU\n",
    "pcMyr2kms = 1.023 # Pc/Myr -> km/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b23f4c9-238d-48c7-a092-26e830c19935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Directories:\n",
      "\n",
      "0 : COMPAS_Output_1%solar_metallicity\n",
      "1 : COMPAS_Output_10%solar_metallicity\n",
      "2 : COMPAS_Output_PeTar_M100000\n",
      "3 : COMPAS_Output_SanaDist_1%metal\n",
      "4 : COMPAS_Output_SanaDist_1%metal_2\n",
      "5 : COMPAS_Output_SanaDist_10%metal\n",
      "6 : COMPAS_Output_SanaDist_10%metal_2\n",
      "7 : COMPAS_Output_SanaDist_solmetal\n",
      "8 : COMPAS_Output_SanaDist_solmetal_2\n",
      "9 : COMPAS_Output_solar_metallicity\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "What directory is the data stored in?   4\n"
     ]
    }
   ],
   "source": [
    "# Selecting directory\n",
    "dataDir = find_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66166d58-a1a9-4680-8efc-ceb4c7f8b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the double compact objects as well as the system parameters\n",
    "DCO = pd.read_csv(os.path.join(dataDir, 'BSE_Double_Compact_Objects.csv'), skiprows=2)\n",
    "SP = pd.read_csv(os.path.join(dataDir, 'BSE_System_Parameters.csv'), skiprows=2)\n",
    "SN = pd.read_csv(os.path.join(dataDir, 'BSE_Supernovae.csv'), skiprows=2)\n",
    "\n",
    "\n",
    "# Find the equilibrated at birth and remove them from the DCOs\n",
    "EAB = SP.loc[SP['Equilibrated_At_Birth']==1] \n",
    "DCO.drop(DCO.loc[DCO['    SEED    '].isin(EAB['    SEED    '])].index, inplace=True)\n",
    "SN.drop(SN.loc[SN['    SEED    '].isin(EAB['    SEED    '])].index, inplace=True)\n",
    "\n",
    "# Remove the invalid values\n",
    "invalidVals = SN.loc[(SN['SystemicSpeed '] == '          -nan')|(SN['SystemicSpeed '] == '          -nan')|(SN['SystemicSpeed '] == '          -nan')]\n",
    "if len(invalidVals)>0:\n",
    "    print('{} systems dropped'.format(len(invalidVals)))\n",
    "    SN.drop(invalidVals.index, inplace=True)\n",
    "\n",
    "SN = SN.astype({'SystemicSpeed ':'float64', \n",
    "                'ComponentSpeed(SN)':'float64', \n",
    "                'ComponentSpeed(CP)':'float64',\n",
    "                'SemiMajorAxis ':'float64'})\n",
    "\n",
    "\n",
    "\n",
    "# Specifically grab the BBHs\n",
    "BBHMaster = DCO.loc[(DCO['Stellar_Type(1)']==14)&(DCO['Stellar_Type(2)']==14)].copy()\n",
    "BBHMaster.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2dc771e2-d027-4f7c-96b3-14a0a9539514",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we find all of the possible BH systems so that we can \n",
    "later find which have been retained.\n",
    "'''\n",
    "\n",
    "# Index for both SNs , only first and only last\n",
    "SNDupIndex = SN.duplicated(subset='    SEED    ', keep=False)\n",
    "\n",
    "SN1st = SN.loc[SN.duplicated(subset='    SEED    ', keep='last')]\n",
    "SN2nd = SN.loc[SN.duplicated(subset='    SEED    ', keep='first')]\n",
    "\n",
    "SN1st.reset_index(drop=True, inplace=True)\n",
    "SN2nd.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Two SNs\n",
    "SNDup = SN.loc[SNDupIndex]\n",
    "SNDup.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Single SN\n",
    "SNSing = SN.loc[~SNDupIndex]\n",
    "SNSing.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# BH other star unbound and bound\n",
    "BHSingUnbound = SNSing.loc[(SNSing['Stellar_Type(SN)']==14)&(SNSing['Unbound']==1)]\n",
    "BHSingBound = SNSing.loc[(SNSing['Stellar_Type(SN)']==14)&(SNSing['Unbound']==0)]\n",
    "\n",
    "BHSingUnbound.reset_index(inplace=True, drop=True)\n",
    "BHSingBound.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# BBHs that remain bound\n",
    "BBHBound = SN.loc[(SN['Stellar_Type(SN)']==14)&(SN['Stellar_Type(CP)']==14)&(SN['Unbound']==0)]\n",
    "BBHBound.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# BH other SN\n",
    "BHElse = SN2nd.loc[((SN2nd['Stellar_Type(SN)']==14)&(SN2nd['Stellar_Type(CP)']!=14))|((SN2nd['Stellar_Type(CP)']==14)&(SN2nd['Stellar_Type(SN)']!=14))]\n",
    "BHElse.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# BBHs that are not bound\n",
    "BBHUnbound = SN.loc[(SN['Stellar_Type(SN)']==14)&(SN['Stellar_Type(CP)']==14)&(SN['Unbound']==1)]\n",
    "BBHUnbound.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3e55e26-d7d1-44ea-9706-8c0d51658902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['    SEED    ', 'Drawn_Kick_Magnitude(SN)',\n",
       "       'Applied_Kick_Magnitude(SN)', 'Fallback_Fraction(SN)',\n",
       "       'Orb_Velocity<SN', 'Kick_Magnitude(uK)', 'True_Anomaly(psi)(SN)',\n",
       "       'SN_Kick_Theta(SN)', 'SN_Kick_Phi(SN)', 'SN_Type(SN)',\n",
       "       'Eccentricity<SN', ' Eccentricity ', 'SemiMajorAxis<SN',\n",
       "       'SemiMajorAxis ', '      Time      ', 'Supernova_State', 'Unbound',\n",
       "       'Stellar_Type(CP)', 'Stellar_Type(SN)', 'Stellar_Type_Prev(SN)',\n",
       "       '   Mass(CP)   ', 'Mass_Total@CO(SN)', 'Mass_Core@CO(SN)',\n",
       "       'Mass_CO_Core@CO(SN)', 'Mass_He_Core@CO(SN)', '   Mass(SN)   ',\n",
       "       'Experienced_RLOF(SN)', 'MT_Donor_Hist(SN)', 'ComponentSpeed(SN)',\n",
       "       'ComponentSpeed(CP)', 'SystemicSpeed ', 'Is_Hydrogen_Poor(SN)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SN.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0e12611a-95b1-4f7b-a379-c5f4c1d64f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here I define either a specific mass or a specific escape velocity \n",
    "'''\n",
    "Mcl = 100 # 3 values of cluster mass (Msol) for open, globular and nuclear clusters densities\n",
    "rh = 2.154 # pc\n",
    "rhoh = (Mcl/2)/(4/3*np.pi*rh**3)\n",
    "\n",
    "vesc = 280 # km/s\n",
    "sigma = vesc/4.77 # km/s\n",
    "\n",
    "# Assumed perturber mass\n",
    "m3=20 # Msol \n",
    "\n",
    "perturberMass = np.array([])\n",
    "\n",
    "# Make a copy of the data\n",
    "BBH_simple = BBHMaster.copy()\n",
    "\n",
    "# Reset the counters\n",
    "retainedSingle=0\n",
    "retainedBound=0\n",
    "\n",
    "# This last part will calculate the fraction of retained binaries (containing at least one BH) with the cluster \n",
    "# Those systems that form a BH but the second star never goes SN\n",
    "retainedSingle+=len(BHSingUnbound.loc[BHSingUnbound['ComponentSpeed(SN)']<vesc])\n",
    "retainedBound+=len(BHSingBound.loc[BHSingBound['ComponentSpeed(SN)']<vesc])\n",
    "\n",
    "# seeds retained from first SN\n",
    "retainedInFirst = SN1st.loc[(SN1st['SystemicSpeed ']<vesc)&(SN1st['Unbound']==0)]\n",
    "retainedSN = SN1st.loc[(SN1st['ComponentSpeed(SN)']<vesc)&(SN1st['Unbound']==1)]\n",
    "retainedCP = SN1st.loc[(SN1st['ComponentSpeed(CP)']<vesc)&(SN1st['Unbound']==1)]\n",
    "\n",
    "# BBHbound retained after second\n",
    "index = BBHBound['    SEED    '].isin(retainedInFirst['    SEED    '])\n",
    "BBHRetain = BBHBound.loc[(BBHBound['SystemicSpeed ']<vesc)&(index)]\n",
    "retainedBound+=2*len(BBHRetain)\n",
    "\n",
    "# BBHUnbound on second\n",
    "index = BBHUnbound['    SEED    '].isin(retainedInFirst['    SEED    '])\n",
    "retainedSingle+=len(BBHUnbound.loc[(index)&(BBHUnbound['ComponentSpeed(SN)']<vesc)])\n",
    "retainedSingle+=len(BBHUnbound.loc[(index)&(BBHUnbound['ComponentSpeed(CP)']<vesc)])\n",
    "\n",
    "# Add single mass to array\n",
    "perturberMass = np.append(perturberMass, BBHUnbound['   Mass(SN)   '].loc[(index)&(BBHUnbound['ComponentSpeed(SN)']<vesc)].values)\n",
    "perturberMass = np.append(perturberMass, BBHUnbound['   Mass(CP)   '].loc[(index)&(BBHUnbound['ComponentSpeed(CP)']<vesc)].values)\n",
    "\n",
    "# BHElse on Second\n",
    "index = BHElse['    SEED    '].isin(retainedInFirst['    SEED    '])\n",
    "retainedBound+=len(BHElse.loc[(index)&(BHElse['SystemicSpeed ']<vesc)&(BHElse['Unbound']==0)])\n",
    "retainedSingle+=len(BHElse.loc[(index)&(BHElse['ComponentSpeed(SN)']<vesc)&(BHElse['Stellar_Type(SN)']==14)&(BHElse['Unbound']==1)])\n",
    "retainedSingle+=len(BHElse.loc[(index)&(BHElse['ComponentSpeed(CP)']<vesc)&(BHElse['Stellar_Type(CP)']==14)&(BHElse['Unbound']==1)])\n",
    "\n",
    "# Add single masses to array\n",
    "perturberMass = np.append(perturberMass, BHElse['   Mass(SN)   '].loc[(index)&(BHElse['ComponentSpeed(SN)']<vesc)&(BHElse['Stellar_Type(SN)']==14)&(BHElse['Unbound']==1)].values)\n",
    "perturberMass = np.append(perturberMass, BHElse['   Mass(CP)   '].loc[(index)&(BHElse['ComponentSpeed(CP)']<vesc)&(BHElse['Stellar_Type(CP)']==14)&(BHElse['Unbound']==1)].values)\n",
    "\n",
    "# retainedUnbound on first\n",
    "retainedSingle+=len(retainedSN.loc[retainedSN['Stellar_Type(SN)']==14])\n",
    "index = SN2nd['    SEED    '].isin(retainedCP['    SEED    '])\n",
    "retainedSingle+=len(SN2nd.loc[(index)&(SN2nd['ComponentSpeed(SN)']<vesc)&(SN2nd['Stellar_Type(SN)']==14)])\n",
    "\n",
    "# Add single masses to array\n",
    "perturberMass = np.append(perturberMass, retainedSN['   Mass(SN)   '].loc[retainedSN['Stellar_Type(SN)']==14].values)\n",
    "perturberMass = np.append(perturberMass, SN2nd['   Mass(SN)   '].loc[(index)&(SN2nd['ComponentSpeed(SN)']<vesc)&(SN2nd['Stellar_Type(SN)']==14)].values)\n",
    "\n",
    "\n",
    "# Append to the fractional arrays\n",
    "totalretained=retainedSingle+retainedBound\n",
    "\n",
    "# Find hard binaries\n",
    "mu = (BBHRetain['   Mass(SN)   ']*BBHRetain['   Mass(CP)   '])/(BBHRetain['   Mass(SN)   ']+BBHRetain['   Mass(CP)   '])\n",
    "ah = (G*mu)/(sigma**2)\n",
    "hardBBH = BBHRetain.loc[BBHRetain['SemiMajorAxis ']<=ah]\n",
    "\n",
    "# Make a distribution of single BH masses \n",
    "values, bins = np.histogram(perturberMass, bins = range(0, round(max(perturberMass)), 1), density = True)\n",
    "bin_mid = np.array([(bins[j+1]+bins[j])/2 for j in range(len(bins)-1)])\n",
    "\n",
    "m_perturb = choices(bin_mid, weights=values, k=len(hardBBH))\n",
    "\n",
    "# Calculate the recoil kick from a single interaction assuming 0.2 energy transfer\n",
    "kick_vel_sq = 0.2 * G/hardBBH['SemiMajorAxis '] * (hardBBH['   Mass(SN)   '] * hardBBH['   Mass(CP)   '])/(hardBBH['   Mass(SN)   '] + hardBBH['   Mass(CP)   '] + m_perturb)\n",
    "\n",
    "# Find hard binaries removed after single interaction\n",
    "removed1st = hardBBH.loc[kick_vel_sq >= vesc**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1ab0d968-7659-4b7a-9c58-ca34b3ba5858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.73092446665386"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(hardBBH) - len(removed1st))/len(hardBBH) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29215ef1-813a-437a-9cce-b780224b1b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(removed1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e45dfb-449c-49a5-803a-11c13617b8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
